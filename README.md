# A Qualitative Study on XAI Techniques for Software Defect Prediction
Ensuring reliable and secure software through effective defect prediction remains a key challenge in software engineering (SE). While traditional machine learning (ML) models excel in predictive performance, their lack of transparency leaves developers unsure about trusting or understanding the predictions. XAI has emerged to address this challenge by improving interpretability and providing actionable insights. Unlike broader reviews focused on general AI or healthcare, this study zeroes in on XAI specifically for software defect prediction, bridging the gap between theory and practical application in software development. Through a systematic review of 106 papers, this research explores popular XAI techniques like LIME, SHAP, PyExplainer, and BreakDown, assessing their role in defect prediction. By incorporating qualitative analysis and scenario-based evaluations, the study identifies inconsistencies in XAI results and introduces metrics like Feature Agreement (FA) to resolve disagreements. The findings provide a clear picture of how these tools perform in real-world development environments, offering developers consistent and interpretable insights to support better decision-making. Additionally, the study highlights challenges such as maintaining consistency across XAI results and balancing model complexity with explainability. A user study with 71 practitioners, including software engineers and ML experts, highlights common issues such as explanation disagreements, installation problems, and integration challenges. Participants emphasized the need for better documentation, simpler tools, and solutions tailored to specific needs. This study shows how XAI can improve decision making and build trust by providing clear, actionable insights. It also identifies opportunities to refine XAI tools, making them more practical and useful for improving software quality.
